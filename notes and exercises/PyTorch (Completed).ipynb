{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sln2hhIj-xMM"
   },
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"float:left\"><h1> PyTorch </h1></div>\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:65px\" src =\"https://drive.google.com/uc?export=view&id=1EnB0x-fdqMp6I5iMoEBBEuxB_s7AmE2k\" />\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rleCdA1nZS7"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Today, we will introduce Torch for Python (`PyTorch`), a deep learning library developed by Facebook and Uber. PyTorch is quickly becoming one of the dominant tools for building deep learning systems in both academic and industry settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Es6K9j4nZS-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xieyj\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# comment this out if you don't have tqdm\n",
    "from tqdm.notebook import tnrange, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqrHhP2nnZTC"
   },
   "source": [
    "### Torch tensors\n",
    "\n",
    "At the centre of any `PyTorch` system, or really any deep learning system, is a **tensor**. A tensor is just a fancy name for a high dimensional array of numbers. We have seen tensors before:\n",
    "* vectors are first order tensors, \n",
    "* two dimensional arrays (matrixes) are second order tensors, and\n",
    "* higher dimensional arrays are third, fourth, etc' order tensors.\n",
    "\n",
    "They are essentially just NumPy arrays re-implemented in `PyTorch`. They are built to interact with other PyTorch features and run on Graphical Processing Units (GPUs). Because GPUs are quite expensive, modern ones run upwards of ten-thousand dollars, we won't take advantage of GPU functionality in this course, but whatever code we write here can easily be ported to any GPU we have access to. \n",
    "\n",
    "Declaring a PyTorch tensor is exactly the same as declaring a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "4N5Jdo3AnZTD",
    "outputId": "2d83e1b4-fca5-4ea7-c4cf-15f2b162ba78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# using the ones function\n",
    "x = torch.ones(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "nMGPr8NG-xMU",
    "outputId": "3b42d2e4-3fc0-473d-f5f3-5e8d22b6c9dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1400, 3.1400, 3.1400],\n",
      "        [3.1400, 3.1400, 3.1400],\n",
      "        [3.1400, 3.1400, 3.1400]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# create a tensor with the same values at every position\n",
    "x = torch.full((3, 3), 3.14, dtype=torch.float64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_2ePDFnZTG"
   },
   "source": [
    "Like NumPy arrays we can combine tensors with scalar values and each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "GscGWxiQnZTG",
    "outputId": "6d951291-b3bc-4167-cbde-630029dd1754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1269, 3.1795, 0.6366],\n",
      "        [3.1656, 3.9972, 4.1321],\n",
      "        [2.5531, 2.9736, 3.2680]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Combining two torch tensors\n",
    "x = torch.full((3, 3), 3, dtype=torch.float64)\n",
    "y = torch.randn(3, 3)\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "XDubfWzA-xMZ",
    "outputId": "9ff22f18-3c0f-4c88-d3bd-0adabd02817b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 12., 12.],\n",
      "        [12., 12., 12.],\n",
      "        [12., 12., 12.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# combining a tensor with a scalar\n",
    "c = 4\n",
    "z = c * x\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D81vXIhnZTJ"
   },
   "source": [
    "Since a tensor is essentially a NumPy array, we won't go into any more detail. We just need to know that anything you can do with a NumPy array you can also do with a PyTorch tensor (maybe with a slight change of syntax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8UHwnYw-xMb"
   },
   "source": [
    "#### Exercise 1\n",
    "\n",
    "1. Create the following tensors:\n",
    "    \n",
    "    * `x`: a tensor of shape (2, 1, 3) of random floats between 1 and 5. What does shape 1 in the middle mean?\n",
    "    * `y`: a tensor of shape (2, 3) that holds the integers from 0 to 5.\n",
    "    \n",
    "    \n",
    "2. Look up what the `squeeze` and `unsqueeze` commands do in `torch`. \n",
    "    \n",
    "    * What happens if you squeeze `x`?\n",
    "    * What happens if you unsqueeze `y`? (Hint: try 0, 1 and 2 for the `dim` argument and check the shapes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UrPYPvCX7V63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.5852, 3.9220, 3.5367]],\n",
       " \n",
       "         [[1.3086, 2.2899, 3.0059]]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 4*torch.rand(2,1,3) + 1\n",
    "y = torch.arange(0,6).reshape(2,3)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruzagD76nZTK"
   },
   "source": [
    "### Backpropagation and Autograd\n",
    "\n",
    "Recall that when neural networks are trained, there are two separate phases: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaTKPZKU7V63"
   },
   "source": [
    "1. In the **forward pass phase**, we pass the input through the network transforming it in each layer until we reach the output. \n",
    "    * At the final output layer, we make our prediction and calculate our loss (or prediction error).\n",
    "    \n",
    "    \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1FVcvkNzLH0cfz7eImr4bPJf2GkJfVmBj\"/>\n",
    "\n",
    "<center> <i>Image prepared using <a href=\"https://alexlenail.me/NN-SVG/index.html\">NN-SVG</a></i> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WykZsJNT7V64"
   },
   "source": [
    "2. In the **backpropagation phase**, we update the network weights according to the training error gradient.\n",
    "    * The gradient tells us what weight change corresponds to a decreased loss. \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1tHwi8veILHxruKh_M5AKdWACpMl7WZPw\"/>\n",
    "<center> <i>Image prepared using <a href=\"https://alexlenail.me/NN-SVG/index.html\">NN-SVG</a></i></center>\n",
    "\n",
    "The second phase can be very difficult as modern networks are highly complex and the gradient calculation is not so easy. This is true especially if we have have complex connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf_kenU-nZTL"
   },
   "source": [
    "PyTorch takes care of calculating the gradient for us, when we combine tensors with each other, just like a network combines different layers. When we define a tensor we just need to indicate that we want to keep track of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "S2EAgLFQnZTM",
    "outputId": "73819e23-571e-442e-a376-0fcbace460f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# specify we need the gradient\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "v9fSZkA9-xMh",
    "outputId": "bcd8c495-52a8-4f85-a70c-be4eec924a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2 + 3\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu0Froiq-xMi"
   },
   "source": [
    "Let's plot our function, the data point and the tangent line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9S8Kuxo7V65"
   },
   "source": [
    "<img width=400 src=\"https://drive.google.com/uc?export=view&id=1QogK1NDTeri34LmOGPQQ-QVWsw6lkRo3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9R9alLg-xMl"
   },
   "source": [
    "What is the gradient of `y` with respect `x`? Thinking geometrically, the gradient gives you the slope of the tangent line at `x=2`. You can already read it from the plotting script that the slope is 4 (or use some calculus).\n",
    "\n",
    "$$\\frac{\\Delta y}{\\Delta x} = 2x$$\n",
    "\n",
    "So when $x = 2$, $2x = 4$. This is stored in the `x.grad` attribute after calling the `backward()` method on the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vGWysoqY-xMm",
    "outputId": "5640b962-0df2-49b6-9af7-97cf6146e142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# calculate gradients which are then stored at the variables\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dotfkNAA-xMn"
   },
   "source": [
    "When `y` will correspond to a loss and `x` to model weights, we can use this gradient to change `x` (the weights) by following the gradient and stepping towards a lower `y` (loss) value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-lK6GcJnZTa"
   },
   "source": [
    "For much more complicated operations, we can still get the gradients using this method and this is a very powerful tool. We can custom-design almost any network architecture and we automatically get the backpropagation done for us. This is incredibly useful, especially on massive networks with millions of complex connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo_rVsdcnZTb"
   },
   "source": [
    "### Defining layers and neural networks\n",
    "\n",
    "The key to building neural networks is combining multiple layers of linear and non-linear functions. This is easy enough in PyTorch. Let's build a network which classifies solves the `breast_cancer` binary classification task. For this, we first load in the data using `sklearn` and turn the `numpy` arrays into `torch` tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MZmuut0Qe5bB",
    "outputId": "4666dd54-53f2-498a-a1d4-acc6b12a4528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([455, 30]) torch.Size([455]) torch.Size([114, 30]) torch.Size([114])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let's use the breask cancer data for this:\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "my_scaler = StandardScaler()\n",
    "X_train = my_scaler.fit_transform(X_train)\n",
    "X_test = my_scaler.transform(X_test)\n",
    "\n",
    "# We have to turn the data into tensors, and in this case, \n",
    "# convert the type from np.float64 to torch.float32\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IadDpNMe5bD"
   },
   "source": [
    "If we only wanted to implement a linear network we can do this with the `Linear` connection functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Vx40bMFcnZTd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XVi-LHQN-xMs"
   },
   "outputs": [],
   "source": [
    "# Go from size 30 to size 8. \n",
    "# This means we have 30 input features, and we are pushing them through \n",
    "# the network to a hidden layer of size 8\n",
    "layer_1 = nn.Linear(30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-ElqoNQM-xMu"
   },
   "outputs": [],
   "source": [
    "# Go from size 8 to size 2, from the 8 neuron hidden layer to a 2 neuron output layer\n",
    "layer_2 = nn.Linear(8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6EcYrSr-xMw"
   },
   "source": [
    "Each layer has a `forward` method that calculates the output of the layer for a given input. But you can simply call the layer to get the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aHAOtiTl-xMx",
    "outputId": "a2adb00c-b050-4c6d-af31-ced2242dde1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0694, 0.4689]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = X_train[[0], :] # one data point with 30 features\n",
    "\n",
    "# Run the data through the layers\n",
    "hidden_values = layer_1(x)\n",
    "output_values = layer_2(hidden_values)\n",
    "\n",
    "print(output_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mE6X2U8nZTi"
   },
   "source": [
    "This was easy enough, although we should probably use the softmax activation for the top layer so that it follows a proper probability distribution. Briefly, if the output of a layer is $x=(x_1,\\cdots , x_d)$ then the softmax output for element $i$ is:\n",
    "\n",
    "$$softmax(x_i) = \\frac{exp(x_i)}{\\sum_j exp(x_j)}$$\n",
    "\n",
    "This softmax formula ensures that the output of the last layer corresponds to probabilities: numbers between 0 and 1 with total sum equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zrhfuV7rnZTi",
    "outputId": "b2740582-797c-4fe2-f465-54ae67a92e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4014, 0.5986]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = X_train[[0], :] # one data point with 30 features\n",
    "\n",
    "# define the layers of our neural network\n",
    "layer_1 = nn.Linear(30, 8)\n",
    "layer_2 = nn.Linear(8, 2)\n",
    "\n",
    "# Run the data through a linear layer\n",
    "hidden_values = layer_1(x)\n",
    "hidden_values = layer_2(hidden_values)\n",
    "\n",
    "# Notice this is a function, not a layer as in TensorFlow\n",
    "output_values = nn.functional.softmax(hidden_values, dim=-1) # makes sure that the output sums to 1 in dimension 1\n",
    "\n",
    "print(output_values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3BKJmJb-xM1"
   },
   "source": [
    "PyTorch has a `Sequential` module that can be used to simplify working with models that pass tensors sequentially through layers. Let's redo our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "1H9ZFMCK-xM1",
    "outputId": "98d096d0-e75e-4fdb-ce44-bb3e6890bfa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=30, out_features=8, bias=True)\n",
       "  (1): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just provide the layers as arguments\n",
    "neural_net = nn.Sequential(nn.Linear(30, 8),\n",
    "                          nn.Linear(8, 2))\n",
    "neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "e2HvETc4-xM3",
    "outputId": "aa53908a-e7d5-4962-8269-d63048652f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6542, 0.3458]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "output_logit_values = neural_net(x)\n",
    "output_values = nn.functional.softmax(output_logit_values, dim=1)\n",
    "print(output_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KK5PBil-xM5"
   },
   "source": [
    "Why did we get a different result now from the same input and same model? The layers (by default) are always initialized with random weights following a certain distribution so when we re-created the model, we initilized with different weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLFftUGjnZTn"
   },
   "source": [
    "When training neural networks, we need to compare our output to a target value. We can calculate how far the output is from the target, which is called the *loss*, and use that measurement to train our network. \n",
    "\n",
    "How we take the difference between the target and output can have an impact on performance. For now, we will use the **cross entropy loss** which is the most prominent loss function for classification. For this, we can actually **skip the softmax layer** in the network because that calculation is built into the `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ot_96tYAnZTp",
    "outputId": "9afe3b7a-3838-4145-d68c-f32c40ca0c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8025, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# the same model except the softmax\n",
    "neural_net = nn.Sequential(nn.Linear(30, 8),\n",
    "                           nn.Linear(8, 2),)\n",
    "\n",
    "# the loss expects the data in batches so we have to specify even if we only have\n",
    "# one data point\n",
    "x = X_train[[0], :] \n",
    "target = y_train[[0]]\n",
    "\n",
    "# FORWARD PASS\n",
    "output_values = neural_net(x)\n",
    "\n",
    "# take the Cross Entropy Loss (includes the softmax calculation so we don't need that in the neural_net)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "loss = cross_entropy_loss(output_values, target) \n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E-swe85nZTr"
   },
   "source": [
    "At this point we have a network, we can do a forward pass and calculate the loss.\n",
    "\n",
    "However, we still haven't done anything to train it. To do training we take the loss and propagate it backwards through the network. Let's do that next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVY2GTQw-xM7"
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "1. Look up the different built-in activation functions in the `torch.nn` module.\n",
    "\n",
    "2. Build a deep neural network using the `Sequential` class that includes linear layers and three different types of activations in-between. The input dimension should be 100 and the output 10. You decide the hidden layer size!\n",
    "\n",
    "3. Test your network by passing through a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBh3lTCq7V69"
   },
   "source": [
    "#### Solution\n",
    "\n",
    "There are a number of available activation functions, some classical include `Sigmoid`, `Tanh`, `ReLU`.\n",
    "\n",
    "We can build a simple network using these with input dim 100 and 10 output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.2 Building a deep neural net\n",
    "\n",
    "neural_net = nn.Sequential(nn.Linear(100, 64),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(64, 32),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(32, 16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always advised to run a quick sanity check to test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.3 testing with a random tensor\n",
    "x = torch.rand(1, 100)\n",
    "output = neural_net(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRnL_UlW-xM8"
   },
   "source": [
    "### Training neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDjTHADS-xM8"
   },
   "source": [
    "To recap the training procedure, we need to\n",
    "* pass forward the input tensor through the network,\n",
    "* backpropagate and calculate the gradients, and\n",
    "* update the network weights to decrease loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhHPxFk-xM9"
   },
   "source": [
    "Let's set up a model and loss function as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WZBfDfy8-xM9"
   },
   "outputs": [],
   "source": [
    "# a single data point\n",
    "x = X_train[[0], :] \n",
    "target = y_train[[0]]\n",
    "\n",
    "# MODEL: setting up our network with an extra activation function and the loss\n",
    "neural_net = nn.Sequential(nn.Linear(30, 8),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(8, 2)\n",
    "                          )\n",
    "# Cross Entropy Loss (includes the softmax calculation so we don't need that in the neural_net)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfTeIfsp-xM_"
   },
   "source": [
    "The network parameters are stored in a generator that we can look into - converting into a list, each element will be the weights for the individual layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "NYvVAOv--xM_",
    "outputId": "35284dce-3c80-4e44-e7fa-fa48b3296700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(neural_net.parameters())[0].shape # the parameters for our 30 X 8 first layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lyz7Q__V-xNB"
   },
   "source": [
    "#### 1. The forward pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWHh6kC8-xNB"
   },
   "source": [
    "We just pass the input and the network takes care of everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "98YAZXch-xNC",
    "outputId": "9da2f430-c6a9-43b0-862c-49d86b7cd9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9811, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# FORWARD PASS\n",
    "output_values = neural_net(x)\n",
    "loss = cross_entropy_loss(output_values, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuawzkG2-xND"
   },
   "source": [
    "You can check that there are no gradients stored yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "iH3DdfDQ-xND",
    "outputId": "8cd910e5-7dad-4933-dbb9-59bcbb29707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(list(neural_net.parameters())[0].grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBJBoN0l-xNF"
   },
   "source": [
    "#### 2. The backward pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AO9gpzx-xNF"
   },
   "source": [
    "We use `backward` as before to calculate the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2Djq48Ca-xNG"
   },
   "outputs": [],
   "source": [
    "# BACKWARD PASS\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1971,  0.1222,  0.1596,  0.0298,  0.0567, -0.1576, -0.0145, -0.0768,\n",
       "         -0.0289,  0.0017,  0.0883, -0.0401,  0.1140,  0.0881, -0.1649, -0.0875,\n",
       "         -0.0214, -0.1319,  0.1159, -0.1043,  0.0261, -0.1560, -0.0056,  0.0763,\n",
       "          0.0508, -0.1588, -0.0061, -0.1088, -0.1480,  0.0058],\n",
       "        [-0.0297,  0.1572, -0.1361,  0.0707, -0.1029,  0.1366, -0.0127,  0.1381,\n",
       "          0.0818,  0.1114, -0.0598, -0.0243,  0.0666,  0.0326,  0.1510,  0.0770,\n",
       "          0.1524,  0.0595,  0.1348, -0.0653, -0.1417,  0.1558,  0.0415,  0.0385,\n",
       "         -0.1467, -0.1397,  0.0764, -0.0145,  0.1529, -0.1427],\n",
       "        [ 0.0377, -0.0951, -0.1393,  0.1744, -0.0842,  0.0095, -0.0310,  0.0040,\n",
       "         -0.1176,  0.1349, -0.0934, -0.1513, -0.0877, -0.0100, -0.1766, -0.0843,\n",
       "         -0.1385,  0.0955,  0.0096, -0.1667,  0.1527, -0.1327, -0.0200,  0.0274,\n",
       "          0.1258,  0.0530, -0.0950, -0.0137,  0.0100, -0.0735],\n",
       "        [ 0.1142,  0.1630,  0.0992,  0.0075,  0.0305,  0.0215, -0.0069,  0.0964,\n",
       "          0.0144, -0.1340,  0.1525, -0.0083,  0.1656,  0.1705,  0.0568, -0.0279,\n",
       "         -0.1438,  0.0668, -0.1505, -0.1816, -0.0112, -0.1186, -0.0006, -0.1318,\n",
       "          0.1432,  0.0959,  0.0756, -0.1501, -0.1246,  0.0902],\n",
       "        [ 0.1411,  0.0530, -0.0580, -0.0042,  0.1112, -0.0077, -0.0081,  0.1711,\n",
       "         -0.1662, -0.0824, -0.1633, -0.0762, -0.1662,  0.1642, -0.1351, -0.0078,\n",
       "          0.1010,  0.0733,  0.0360, -0.0197, -0.0828,  0.0774, -0.1434, -0.0850,\n",
       "          0.1705, -0.0251, -0.1267,  0.1033,  0.0183,  0.0154],\n",
       "        [-0.0414,  0.0247,  0.1304,  0.0683, -0.0707,  0.0247, -0.0675,  0.0238,\n",
       "          0.1177, -0.0340, -0.1600,  0.1721, -0.0856, -0.0344, -0.0375, -0.0382,\n",
       "          0.0713,  0.0986,  0.1635, -0.1374, -0.0430,  0.0161, -0.0463, -0.0529,\n",
       "          0.0174, -0.1636, -0.0084,  0.0123,  0.0405,  0.0075],\n",
       "        [-0.1496,  0.1215,  0.1258,  0.1198,  0.0743, -0.0727, -0.1659,  0.1070,\n",
       "          0.0668, -0.1767,  0.0053, -0.1808, -0.0922,  0.0795, -0.0811,  0.0597,\n",
       "         -0.0727, -0.1807, -0.1572,  0.0490, -0.0751, -0.0043, -0.0968,  0.1307,\n",
       "          0.0762,  0.0412, -0.0142,  0.0758,  0.0675, -0.0691],\n",
       "        [-0.0968, -0.1501, -0.1487, -0.1166, -0.1780,  0.0268,  0.1703,  0.0579,\n",
       "         -0.1081, -0.0154,  0.0140,  0.0332, -0.1454, -0.1169,  0.0592,  0.1130,\n",
       "         -0.0540,  0.0760, -0.0722, -0.0067, -0.1191,  0.0120, -0.1221, -0.0271,\n",
       "         -0.0552,  0.1161,  0.1330,  0.0644, -0.1538, -0.0666]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(neural_net.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3s5gN3bE-xNH"
   },
   "source": [
    "We can see that the gradients are populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "qF7qScp8-xNI",
    "outputId": "4f29c118-386a-438a-a1af-fef39965ac2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2474,  0.0091, -0.2428, -0.2184,  0.0515, -0.0851, -0.1783, -0.2310,\n",
       "          0.3492,  0.0677, -0.0485,  0.1433, -0.0712, -0.0988,  0.0368, -0.0445,\n",
       "         -0.0233, -0.1222,  0.1872, -0.0332, -0.2362, -0.0821, -0.2374, -0.2049,\n",
       "         -0.1137, -0.1614, -0.2177, -0.3008, -0.0274, -0.1118],\n",
       "        [-0.0261,  0.0010, -0.0256, -0.0230,  0.0054, -0.0090, -0.0188, -0.0243,\n",
       "          0.0368,  0.0071, -0.0051,  0.0151, -0.0075, -0.0104,  0.0039, -0.0047,\n",
       "         -0.0025, -0.0129,  0.0197, -0.0035, -0.0249, -0.0086, -0.0250, -0.0216,\n",
       "         -0.0120, -0.0170, -0.0229, -0.0317, -0.0029, -0.0118],\n",
       "        [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.2066, -0.0076,  0.2027,  0.1824, -0.0430,  0.0711,  0.1489,  0.1929,\n",
       "         -0.2916, -0.0565,  0.0405, -0.1197,  0.0595,  0.0825, -0.0307,  0.0371,\n",
       "          0.0195,  0.1021, -0.1563,  0.0277,  0.1972,  0.0685,  0.1982,  0.1711,\n",
       "          0.0949,  0.1348,  0.1818,  0.2512,  0.0229,  0.0933],\n",
       "        [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.3112,  0.0114, -0.3054, -0.2748,  0.0648, -0.1071, -0.2243, -0.2906,\n",
       "          0.4392,  0.0851, -0.0610,  0.1803, -0.0896, -0.1243,  0.0463, -0.0560,\n",
       "         -0.0293, -0.1538,  0.2355, -0.0417, -0.2971, -0.1032, -0.2986, -0.2577,\n",
       "         -0.1430, -0.2030, -0.2738, -0.3784, -0.0345, -0.1406]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(neural_net.parameters())[0].grad # Now we have 30 X 8 gradients (weight adjustments) for \n",
    "                                            # our 30 X 8 weight first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGrAasog-xNJ"
   },
   "source": [
    "#### 3. Update the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GqdsfW--xNK"
   },
   "source": [
    "<center>\n",
    "<img width=\"400px\" src=\"https://drive.google.com/uc?export=view&id=132EC8scZRTefNsBLaWxE7pU6AqoQGPPI\"/>\n",
    "</center>\n",
    "<br/>\n",
    "\n",
    "The weight update is handled by optimizers in PyTorch. Standard choices include `SGD` (Stochastic Gradient Descent) or `Adam`. The optimizer objects needs the model parameters when initialized and other hyperparameters as arguments, such as the *learning rate*. \n",
    "\n",
    "The learning rate defines how large are the steps that we take when we follow the gradient in the weight updates and move towards lower loss values. A large learning rate can make training faster initially but it can also overshoot and jump over an optimal weight. A standard choice for learning rate is `1e-3`.\n",
    "\n",
    "Once we have our weight adjustments $\\frac{\\delta L}{\\delta W}$ (change in loss function based on weights), and our learning rate $\\alpha$, we update the weights according to the following formula:\n",
    "\n",
    "$$W_{new} = W_{old} - \\alpha \\frac{\\delta L}{\\delta W}$$\n",
    "    \n",
    "Where we subtract the adjustments to get to a minimum of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iFM9VtkD-xNK"
   },
   "outputs": [],
   "source": [
    "# setup optimizer (this is only done once, usually with model setup)\n",
    "optimizer = torch.optim.SGD(neural_net.parameters(), lr=0.1)\n",
    "\n",
    "# UPDATE WEIGHTS: the optimizer uses the gradients stored in the neural net and makes a weight update\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IOxU4Sj-xNL"
   },
   "source": [
    "Hopefully, we will see a lower loss if we do a forward pass again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Di8bzLmj-xNM",
    "outputId": "81a996a6-aa7c-4414-a396-aaa67139ebc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old loss: 0.9811255931854248\n",
      "New loss: 0.6475521922111511\n"
     ]
    }
   ],
   "source": [
    "new_output = neural_net(x)\n",
    "new_loss = cross_entropy_loss(new_output, target)\n",
    "print(f\"Old loss: {loss}\\nNew loss: {new_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87peJCJnpah1"
   },
   "source": [
    "### Putting it All Together\n",
    "\n",
    "\n",
    "Let's put our example all together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "8Qwa3NMVpggi",
    "outputId": "4cc6a9d5-b43a-4d0f-fa8b-eaec7a106a82"
   },
   "outputs": [],
   "source": [
    "x = X_train[[0], :] \n",
    "target = y_train[[0]]\n",
    "\n",
    "# MODEL: setting up our network with an extra activation function and the loss\n",
    "neural_net = nn.Sequential(nn.Linear(30, 8),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(8, 2))\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# setup optimizer (this is only done once, usually with model setup)\n",
    "optimizer = torch.optim.SGD(neural_net.parameters(), lr=0.1)\n",
    "\n",
    "# FORWARD PASS\n",
    "output_values = neural_net(x)\n",
    "loss = cross_entropy_loss(output_values, target)\n",
    "\n",
    "# BACKWARD PASS\n",
    "loss.backward()\n",
    "\n",
    "# UPDATE WEIGHTS: the optimizer uses the gradients stored in the neural net and makes a weight update\n",
    "optimizer.step()\n",
    "\n",
    "new_output = neural_net(x)\n",
    "new_loss = cross_entropy_loss(new_output, target)\n",
    "print(f\"Old loss: {loss}\\nNew loss: {new_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDmzVfjwp0pS"
   },
   "source": [
    "While the `Sequential` API is really convenient, most PyTorch code is written using Object Oriented Programming.\n",
    "\n",
    "Most uses of PyTorch to create a neural network will use the `nn.Module` class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "AGRu1sRatFOG"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Basic multi-layer architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network\"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(30, 8) # transition from input into hidden layer\n",
    "        self.activation_1 = nn.ReLU()   # Activation function\n",
    "        self.layer_2 = nn.Linear(8, 2)  # transition from hidden layer into output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "            \n",
    "        # pass through the layers\n",
    "        hidden_1 = self.activation_1(self.layer_1(x))\n",
    "        output = self.layer_2(hidden_1)\n",
    "        \n",
    "        # return output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        The class based interface allows you \n",
    "        add your own functionality, like a familiar\n",
    "        .predict method we all know and love\n",
    "        '''\n",
    "        \n",
    "        # Predict class probabilities\n",
    "        predictions = self.forward(x)\n",
    "        \n",
    "        # Find highest class prediction, notice we don't need to convert to\n",
    "        # probabilities to do hard predictions, we can simply choose the \n",
    "        # highest values\n",
    "        hard_class_predictions = torch.argmax(predictions, dim=1)\n",
    "        \n",
    "        return hard_class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GAPyRStxtFnt"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model, the loss criterion, and the optimizer\n",
    "NN_model = SimpleNN()\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss() # this includes the softmax\n",
    "optimizer = torch.optim.SGD(NN_model.parameters(), lr=.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2w_rjSFf_ug"
   },
   "source": [
    "Instead of passing a single data point, we will now pass the whole training set, calculate the losses and the gradients and update the weights 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "77ab9a58e7d64db0b16e16ae9762c955",
      "429c50009273481b8c34e5a48e325a53",
      "feb53e7a895b4a64be2bbf9a2669aee8",
      "3e047beefd6141bca64b65b6f8341f9f",
      "111b298a8eb94eb7bf90b55435b034fe",
      "ce2f4024aec349448e1ad8c9d5bf0850",
      "a7c91a493549482b859ceb8d14633d93",
      "7c87b9cf462446f58eba68b49d967598",
      "ab58169c27a14ee9b3a61c40660e05cc"
     ]
    },
    "id": "aQxLfKsVtFqz",
    "outputId": "3dfd988d-01c2-445f-97e6-8e1e0656d15c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eecfa967764e03b40ff266f7984eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization ended successfully\n"
     ]
    }
   ],
   "source": [
    "# Now run for 100 epochs\n",
    "for epoch in tnrange(100, desc=\"Total epochs: \"):\n",
    "  \n",
    "    # Clear gradients (pytorch accumulates gradients by default)\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    # Calculate outputs\n",
    "    output_values = NN_model(X_train)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = cross_entropy_loss(output_values, y_train) \n",
    "\n",
    "    # Backpropagation & weight adjustment\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Optimization ended successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPGeV1_cydbu"
   },
   "source": [
    "We can now also test our networks performance by moving the data through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RqqJcD3ItFtw",
    "outputId": "025d35ea-7114-422c-c687-503997e87a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 97.37%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "binary_classification = NN_model.predict(X_test)\n",
    "\n",
    "# Calculate the score on the test set\n",
    "accuracy = accuracy_score(y_test, binary_classification)\n",
    "print(f\"Accuracy score on test set: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLPOsngT-xNN"
   },
   "source": [
    "In practice, we would do thousands or even millions of weight updates to get a good model, looping over the forward-backprop-update cycle for each epoch. This is done until the loss and/or other problem-specific metrics converge to an acceptable value or model performance ceases to substantially improve on the validation set (in which further epochs would only result in overfitting). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilyDHXQK7V7C"
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "1. Build a regression neural network using the `Sequential` model for the California Housing dataset. This is a regression problem so remember to choose an appropriate [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions). Use at least 2 hidden layers.\n",
    "\n",
    "2. Train your model for 100 epochs, and then score it, what scoring metric did you choose and how well did the model perform?\n",
    "\n",
    "3. Repeat steps 1 and 2 but with the `class` based interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "42houblG7V7C"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "california = fetch_california_housing()\n",
    "\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "my_scaler = StandardScaler()\n",
    "X_train_scaled = torch.tensor(my_scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "X_test_scaled = torch.tensor(my_scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "28YAJ6ET7V7C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train_scaled.shape[1], 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,1)\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Basic multi-layer architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network\"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(8, 32) # transition from input into hidden layer\n",
    "        self.activation_1 = nn.ReLU()   # Activation function\n",
    "        self.layer_2 = nn.Linear(32, 16)\n",
    "        self.layer_3 = nn.Linear(16,1)# transition from hidden layer into output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "            \n",
    "        # pass through the layers\n",
    "        hidden_1 = self.activation_1(self.layer_1(x))\n",
    "        hidden_2 = self.activation_1(self.layer_2(hidden_1))\n",
    "        output = self.layer_3(hidden_2)\n",
    "        \n",
    "        # return output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        The class based interface allows you \n",
    "        add your own functionality, like a familiar\n",
    "        .predict method we all know and love\n",
    "        '''\n",
    "        \n",
    "        # Predict class probabilities\n",
    "        predictions = self.forward(x)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90df8cef221c446386834182fba27056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total epochs:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tnrange(500, desc = \"Total epochs: \"):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(X_train_scaled)\n",
    "    loss = mse_loss(y_train, output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35752.62129306793"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "test_pred = model(X_test_scaled)\n",
    "err = mean_absolute_error(test_pred.detach().numpy(), y_test.numpy())*100000\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNrvytsG7V7C"
   },
   "source": [
    "### Keras & Tensorflow or PyTorch?\n",
    "\n",
    "There are many several reasons why organizations might choose one of these frameworks over the other.\n",
    "\n",
    "Keras and PyTorch follow two different neural network design methodologies; Keras focuses on quickly building and deploying sequential architectures. Building models and training them is easy, but debugging them is difficult since much of the code is abstracted. On the other hand, PyTorch development follows an approach of building the code almost entirely from fundamental building blocks, so every step can be inspected and debugged more easily. Tensorflow has this functionality as well, but since the introduction of Keras it is less frequently used, especially by data scientists (vs. machine learning engineers).\n",
    "\n",
    "In previous releases of Tensorflow, some neural networks constructed would be limited to a predefined input size (*e.g.* for recurrent neural networkss all sentences must be padded to the same length). This led some organization to switch to PyTorch, which allowed variable size input to be processed for recurrent architectures. Tensorflow 2.0 introduced \"[Eager Execution](https://www.tensorflow.org/guide/eager)\" which enables this advanced functionality, but the organizations that switched may have much of their infrastructure set up in PyTorch by now.\n",
    "\n",
    "PyTorch has been the preferred neural network library in academia. This means many new advances in neural networks that come from research might be implemented in PyTorch rather than Tensorflow, though this trend is evolving as the two libraries mature and with the release of TF 2.x and integration of Keras into Tensorflow's core product.\n",
    "\n",
    "Generally, when going into industry your \"choice\" of neural network framework will often be dictated by the organization. However, for most projects, both libraries will cover the vast majority of needs for deep learning (albeit implemented in different ways) and only for some unique applications might better suited with the choice of one over the other. Given the option, you should use whichever you are most comfortable with, though a practicing data scientist would of course be expected to be knowledgeable and have a baseline level of proficiency with both frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWucikyk7V7D"
   },
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzA7es2q7V7D"
   },
   "source": [
    "## Supplementary - Softmax Layers\n",
    "\n",
    "While we employed the `nn.functional.softmax` function to produce probability distributions from our final layer outputs, you will likely also see the use of the `nn.Softmax` layer in PyTorch.\n",
    "\n",
    "Since `nn.CrossEntropyLoss()` includes the softmax conversion, we don't need the softmax layer during training, but we **might** need it during prediction. This switch is usually controlled using the `self.training` attribute of neural networks (which is inherited from `nn.Module` for us).\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZM40Bgv7V7D"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Basic multi-layer architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network\"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(30, 8) # transition from input into hidden layer\n",
    "        self.activation_1 = nn.ReLU()   # Activation function\n",
    "        self.layer_2 = nn.Linear(8, 2)  # transition from hidden layer into output\n",
    "        \n",
    "        # Declare a softmax layer\n",
    "        self.softmax_layer = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "            \n",
    "        # pass through the layers\n",
    "        hidden_1 = self.activation_1(self.layer_1(x))\n",
    "        hidden_2 = self.layer_2(hidden_1)\n",
    "        \n",
    "        # Notice the network will behave differently based on\n",
    "        # whether it is training or not\n",
    "        if self.training is True:\n",
    "            output = hidden_2\n",
    "        else:\n",
    "            output = self.softmax_layer(hidden_2)\n",
    "        \n",
    "        # return output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grgzlk5F7V7D"
   },
   "source": [
    "The network above changes its behavior based on its training status. So when we train it, we can employ the same code as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyjVZ1mS7V7D"
   },
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "my_scaler = StandardScaler()\n",
    "X_train = my_scaler.fit_transform(X_train)\n",
    "X_test = my_scaler.transform(X_test)\n",
    "\n",
    "# We have to turn the data into tensors, and in this case, \n",
    "# convert the type from np.float64 to torch.float32\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iILWorl57V7D"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model, the loss criterion, and the optimizer\n",
    "NN_model = SimpleNN()\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss() # this includes the softmax\n",
    "optimizer = torch.optim.SGD(NN_model.parameters(), lr=.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "27c594638c944a9187c1168de15a8c0c"
     ]
    },
    "id": "LIxlxdNx7V7D",
    "outputId": "f3f4c3fa-6c1a-4c10-9f50-dea4f3fb2741"
   },
   "outputs": [],
   "source": [
    "# Now run for 100 epochs\n",
    "for epoch in tnrange(100, desc=\"Total epochs: \"):\n",
    "  \n",
    "    # Clear gradients (pytorch accumulates gradients by default)\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    # Calculate outputs\n",
    "    output_values = NN_model(X_train)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = cross_entropy_loss(output_values, y_train) \n",
    "\n",
    "    # Backpropagation & weight adjustment\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Optimization ended successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEgRiuE87V7E"
   },
   "source": [
    "This network will not output a probability distribution by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY-xbCMj7V7E",
    "outputId": "8291b233-0b8a-4a6d-ade0-b466588d72a0"
   },
   "outputs": [],
   "source": [
    "NN_model(X_test[0]) # get the output for the first test data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-pGEh2D7V7E"
   },
   "source": [
    "However, we can switch it to \"evaluation mode\" to trigger the desired behavior we coded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtZRDWWM7V7E",
    "outputId": "cb551b37-8fe5-4c6c-bbe5-29a123d23667"
   },
   "outputs": [],
   "source": [
    "NN_model.eval()\n",
    "NN_model(X_test[0]) # Now we get the output as a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFRrRNI_7V7E"
   },
   "source": [
    "And we can switch the behavior back to training mode as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXJZNqVv7V7E",
    "outputId": "66720ddd-bd9c-4f6e-84d8-290fb4b08bc1"
   },
   "outputs": [],
   "source": [
    "NN_model.train()\n",
    "NN_model(X_test[0]) # get the output for the first test data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyYfhqEO7V7E"
   },
   "source": [
    "PyTorch is largely designed to be more modular than TensorFlow, and as such requires a stronger knowledge of Object Oriented Programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ddszJol7V7F"
   },
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dynot_CJnZT9"
   },
   "source": [
    "## Supplementary - Image classification using CNNs\n",
    "\n",
    "Now we'll work through an example of building a network for a complex data set called **CIFAR-10**. It contains color images of various objects with corresponding labels from 10 possibilities. **It is a classification problem and our goal is to predict what object is in the image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkcRIIhcnZT-"
   },
   "source": [
    "Right now CIFAR-10 contains 32x32 images with 3 color channels (RGB). You can think of each images as a 32x32x3 tensor. Let's load this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "44f933f34ce5421181f587b8651efb1a",
      "0c58a233b2734de2b98f8854f6f02703",
      "e7c2c23dcadd4dc4a80115bf3e7e1133",
      "b68960e273b04f07b6b53e76d7cf0e89",
      "88fa81edd8af4b538c76307b33031ddf",
      "538b92bc691344b9b7a914e400e59dc6",
      "d5711cf01c6b4012ad12fe368fa8fb14",
      "b21bd7e5865f4f6886bd0b14017dab3d"
     ]
    },
    "id": "2OrDNajrnZUA",
    "outputId": "2ed27611-e47a-4121-a8dd-2ed0b2da1239"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', \n",
    "                                     train=True, # whether the train or test set should be loaded\n",
    "                                     download=True, # download data if necessary\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vB32vW1-xNQ"
   },
   "source": [
    "We can take a sample of the images and use `imshow` from `matplotlib` to take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "id": "3Gv7NUpO-xNQ",
    "outputId": "b25c4827-be27-4669-8b17-e77ae9c32795"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cifar_classes = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat',\n",
    "                4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(15, 15))\n",
    "\n",
    "# select random indices\n",
    "indices = np.random.choice(len(train_dataset), len(axs.reshape(-1)))\n",
    "\n",
    "# plot the images in the grid\n",
    "for index, axs in zip(indices, axs.reshape(-1)):\n",
    "    image, label = train_dataset[index]\n",
    "    axs.imshow(image)  # plot the data\n",
    "    axs.axis('off')\n",
    "    axs.set_title(cifar_classes[label])\n",
    "\n",
    "plt.suptitle('CIFAR-10 random sample', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhqBk0ei-xNS"
   },
   "source": [
    "We can take a look at the class distributions and see that we have a balanced classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "G0ZhF_a4-xNS",
    "outputId": "53d9333d-0a02-427e-e377-73ac5a7d5bb4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(cifar_classes.keys(), np.bincount(train_dataset.targets))\n",
    "ax.set_xticks(list(cifar_classes.keys()))\n",
    "ax.set_xticklabels(cifar_classes.values(), rotation=45)\n",
    "plt.title(\"Class distribution for CIFAR10\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7in4gDew-xNU"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Now, we need to turn the data into a tensor object that `torch` can use and we should also normalize the data to improve classifier performance.  \n",
    "\n",
    "Both of these goals can be accomplished using the `transforms` package in PyTorch. This is like building a pipeline: \n",
    "\n",
    "* first we turn the data to a Tensor, \n",
    "* then we scale it specifying the mean and standard deviation of each color channel.\n",
    "\n",
    "Now we can load up CIFAR-10 passing along our `pre_process` object to clean and format the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "2dtul2fXnZT_",
    "outputId": "ba6d32ff-ad71-407f-8b46-3de46123bfe7"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# The normalize values are just set to something that tends to work for this dataset... (totally scientific)\n",
    "pre_process = transforms.Compose([transforms.ToTensor(),  # turn images into tensor\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalize by \n",
    "                                                                                           # subtracting 0.5 (mean)\n",
    "                                                                                           # and dividing by 0.5\n",
    "                                                                                           # to bring all values from\n",
    "                                                                                           # [0,1] to [-1, 1]\n",
    "                \n",
    "# reload the train and test data with our preprocessing\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', \n",
    "                     train=True, \n",
    "                     download=True, \n",
    "                     transform=pre_process\n",
    "                    )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', \n",
    "                     train=False, # use the test portion of the data\n",
    "                     download=True, \n",
    "                     transform=pre_process\n",
    "                    )\n",
    "\n",
    "print(f\"\\nTrain data set size: {len(train_dataset)}\\nTest data set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hhzCSNq-xNW"
   },
   "source": [
    "### Model setup\n",
    "\n",
    "To actually do classification, we'll use a **convolutional neural network**: this is a highly structured network with complex activation and connections between neurons specifically designed to extract features from complex, high-dimensional data sources.\n",
    "\n",
    "Larger and deeper examples of this network often achieve state of the art performance on tasks in a variety of areas, especially for computer vision tasks. As before, we need to build the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf7z2Ahi-xNX"
   },
   "source": [
    "The network we build is essentially sequential and consists of two parts: \n",
    "\n",
    "* a convolutional part that extracts the image features, and\n",
    "* a fully-connected part that makes the prediction based on the extracted features.\n",
    "\n",
    "Between these two parts, we need to reshape our tensors so instead of using two sequential blocks separately, we wrap everything by the `nn.Module` class that is the base class for all neural networks in `torch`. The only thing we need to specify is a `forward` method and after that, we are free to call all the other methods (such as `backward`) that we had for a sequential model before.\n",
    "\n",
    "We also made the design choice to include the loss and optimizer in the model object, which will make our code look more neat later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hW6f2nu-xNX"
   },
   "outputs": [],
   "source": [
    "class MultilayerCNN(nn.Module):\n",
    "    \"\"\"Basic multi-layer CNN architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network including the loss and optimizer.\"\"\"\n",
    "        super(MultilayerCNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Convolutional block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional block 2\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "           \n",
    "            # Convolutional block 3\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        ) # the size of the flattened output tensor will be 64*128 // (2*2)\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*128 // (2*2), 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "        self.softmax_layer = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=.001, momentum=0.9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        # pass through the convolutional layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten the output of the convolution\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # pass through the fully connected layers\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        if not self.training:\n",
    "            x = self.softmax_layer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Get hard class predictions from the \n",
    "        feature data\n",
    "        '''\n",
    "        predictions = self.forward(x)\n",
    "        \n",
    "        # Find highest class logit, notice we don't need to convert to\n",
    "        # probabilities to do hard predictions, we can simply choose the \n",
    "        # highest values\n",
    "        hard_class_predictions = torch.argmax(predictions, dim=1)\n",
    "        \n",
    "        return hard_class_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEIglSXM-xNZ"
   },
   "source": [
    "Let's test our model by running a single image through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "51r9oB3A-xNa",
    "outputId": "ac8026e5-9345-438e-da9b-94b417d76c10"
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "CNN_model = MultilayerCNN() \n",
    "\n",
    "# take the first training example\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# pass it through the model\n",
    "outputs = CNN_model(image.unsqueeze(0))\n",
    "\n",
    "# find the loss\n",
    "CNN_model.cross_entropy_loss(outputs, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgsJBAEZ-xNf"
   },
   "source": [
    "Let's talk a bit about the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "qEDJUziQ-xNf",
    "outputId": "3992c91d-ea84-4ec4-889d-57397c6035c1"
   },
   "outputs": [],
   "source": [
    "print(CNN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ouN3eeP-xNi"
   },
   "source": [
    "First, looking at the convolutional layer:\n",
    "\n",
    "`nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)` \n",
    "\n",
    "This is a standard convolution operation which takes an image with depth 3 (being the first layer, the RGB channels in our case) and learns a 32-depth convolution using 3-by-3 windows. Next:\n",
    "\n",
    "`nn.MaxPool2d(kernel_size=2, stride=2)`\n",
    "\n",
    "This is similar to rolling a convolution window (of size 2x2) with a stride of two pixels but, instead of taking some convolution function, we output the max value in that window. This does two things: it shrinks the image and emphasizes the most prominent values in that window. It is important to note that we pool the max values only along the height and width, not the depth. We apply the pooling to each depth, but we do not combine along depths. That is, this shrinks the height and width of an image but not the depth.\n",
    "\n",
    "The final fully-connected layers are essentially a small feed-forward neural network with one hidden layer and one output layer. This network takes in our convolution of convolutions and outputs a decision (the unnormalized probabilities in our case). You can think of the convolutional units as doing complex feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RU3e15r-xNi"
   },
   "source": [
    "### Training\n",
    "\n",
    "We now need to put the data into a format the model can iterate through. The standard PyTorch interface is the `DataLoader` object. We can either pass in an existing PyTorch dataset or one we put together. We'll pass in the CIFAR-10 training data to get back an object we can iterate through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHR3xU4LnZUQ"
   },
   "outputs": [],
   "source": [
    "# this iterator returns four training examples at a time\n",
    "# so we will update the model after every 4 images\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# this iterator returns 1024 test examples at a time (for fast testing)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iFn6ze0nZUS"
   },
   "source": [
    "Before we train the network let's see its performance on the test set and we'll use classification accuracy as our metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6lMFgBbqnZUS",
    "outputId": "b307341a-e551-40ac-ce84-a2bbd0a2d8f5"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataloader):\n",
    "    '''\n",
    "    Helper function to get classification accuracy for a model over the items in dataloader.\n",
    "    taken from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    # Go through all of the data\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch\n",
    "\n",
    "        # Get the prediction of the net on the images\n",
    "        predicted = model.predict(images)\n",
    "\n",
    "        \n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Count those we got correct\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return(100 * correct / total)\n",
    "\n",
    "\n",
    "print(f\"Pre training accuracy: {get_accuracy(CNN_model, test_dataloader)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_89ouGuWnZUU"
   },
   "source": [
    "That's basically random guessing, which makes sense since the network parameters are totally random right now.\n",
    "\n",
    "We can now iterate through the data updating the parameters with backpropagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215,
     "referenced_widgets": [
      "fdf8c854c1664e3eb100a3efcedc2c73",
      "31eaea7a6aaa46a3a4f76668ce21bcc1",
      "90c85db8a5014df1839233b7cacd5daa",
      "210dcabc206446d5929c71ec19d0daa0",
      "9dee2becf77342cb83efa992e48b2bfc",
      "ce9349b1ad3948f9ba9cd2ccee3d91be",
      "9b7165ffd0a5450b92dbfdcec2e41b35",
      "b683d45eea3d495a88f189c3115d8c33",
      "0532641b2afa45519e52cd3e829c88cc",
      "59a57751bf0c4bb2b667cb02456633cf",
      "dcfc9e22ae0342d09c08f31a98f7f17e",
      "3c6afa5c29d844e995fe8c42aae193e2",
      "002a962bd9ea4c279af3e0f9a9c71bfb",
      "29e9aa1de2dd4bd98392e42e8325de4b",
      "a4b6700f527c4407af1bd00b7001abd9",
      "76485cbb91484b4eab6cafb19ae81687",
      "6af7b49d1ae544b5893bd622b0f6d63e",
      "5851c7f2ea1e417e81a271d735314fe2",
      "d931e2ee657243b592df59197e48991d",
      "3eb405247a4f43788d8dd84b3decbfa1",
      "d85bc0a5ce3e4261ad9294f1a0f288ff",
      "980cffa23d9f48e28597d0d854281d4f",
      "37484f85f8cf48719e9384bd3d096018",
      "73db760e8951472680fbc843dd2ebf2b",
      "f39d5ab214624d3098544ffbc4a0d9c9",
      "12c486f4effe4d0ea89469d7f5b03942",
      "c0bda58892fe4f658ec647b3216458f4"
     ]
    },
    "id": "75J5qQEDnZUW",
    "outputId": "114a2c56-aa87-403b-d93d-61c14ab7d3b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# re-initiliaze the model\n",
    "CNN_model = MultilayerCNN()\n",
    "\n",
    "\n",
    "# MAIN EPOCH LOOP: the epochs are the number of times we loop through the entire training set.\n",
    "for epoch in tnrange(2, desc=\"Total epochs: \"):\n",
    "    \n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    \n",
    "    # BATCH LOOP: loop over the data batches using the data loader \n",
    "    # if you don't have tqdm installed, just use this simpler for-loop instead\n",
    "    # for batch in train_dataloader: \n",
    "    for batch in tqdm_notebook(train_dataloader, desc=f\"Epoch {epoch}: \"):\n",
    "\n",
    "        # get the inputs\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # FORWARD PASS and loss calculation\n",
    "        outputs = CNN_model(inputs)\n",
    "        loss = CNN_model.cross_entropy_loss(outputs, labels)\n",
    "        \n",
    "        # BACKWARD PASS but zero the gradients first to delete the old ones\n",
    "        # as pytorch accumulates gradients by default\n",
    "        CNN_model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # UPDATE: the model weights are updated\n",
    "        CNN_model.optimizer.step()\n",
    "        \n",
    "        # MONITORING: save loss and accuracy on the batch to track the training\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # Get the prediction of the net on the images\n",
    "        predicted = CNN_model.predict(inputs)\n",
    "        acc_sum += (labels == predicted).sum().item() / labels.shape[0]\n",
    "        \n",
    "    \n",
    "    # print summary of training metrics\n",
    "    loss_avg = loss_sum / len(train_dataloader)\n",
    "    acc_avg = acc_sum / len(train_dataloader)\n",
    "    test_acc = get_accuracy(CNN_model, test_dataloader)\n",
    "    \n",
    "    print(f\"Avg loss: {np.round(loss_avg, 4)} | \"\\\n",
    "          f\"Avg training accuracy: {np.round(acc_avg*100, 2)} | \"\\\n",
    "          f\"Avg test accuracy: {np.round(test_acc, 2)}\")\n",
    "\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cxncv_6jnZUb"
   },
   "source": [
    "We see there has been a substantial improvement (~65-70% test accuracy) and we only ran through the training set twice. In general, you'd want to train your model for several more epochs and only stop when the test accuracy stops to decrease. As a last step, we can save our model parameters. More info about saving and loading models in Pytorch [can be found here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJte5UFO-xNp"
   },
   "outputs": [],
   "source": [
    "# save the state model of the trained model\n",
    "torch.save(CNN_model.state_dict(), \"trained_CNN_state.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IdOGbCnZU2"
   },
   "source": [
    "### Model Evaluation in Detail\n",
    "\n",
    "First, we will reload the pre-trained `MultilayerCNN` model using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "vB46YnJp-xNr",
    "outputId": "00392083-e997-411a-e93f-872da3c79e8f"
   },
   "outputs": [],
   "source": [
    "# Loading models from states: you initialize the architecture and load in the state dictionary.\n",
    "\n",
    "new_CNN_model = MultilayerCNN()\n",
    "new_CNN_model.load_state_dict(torch.load(\"trained_CNN_state.pt\"))\n",
    "\n",
    "# print out to see the model details\n",
    "new_CNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_iFBgeb-xNs"
   },
   "source": [
    "Once we have the model, we'll evaluate it by looking at the confusion matrix. This code will save your predictions and labels on the test data and plot the confusion matrix. What are the classes that are often mixed up by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "NnkLXUkw-xNt",
    "outputId": "bc06023e-e702-47c0-d583-9b5d003d0be9"
   },
   "outputs": [],
   "source": [
    "#Evaluate the confusion matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# save the prediction and labels as we loop through the data\n",
    "label_list = []\n",
    "prediction_list = []\n",
    "\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    images, labels = batch\n",
    "    predicted = new_CNN_model.predict(images)\n",
    "\n",
    "    label_list.extend(list(labels.numpy()))\n",
    "    prediction_list.extend(list(predicted.numpy()))\n",
    "\n",
    "        \n",
    "# calculate the confusion matrix and plot\n",
    "cm = confusion_matrix(label_list, prediction_list, normalize=\"true\")\n",
    "\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=class_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp = disp.plot(xticks_rotation='vertical', ax=ax, cmap='summer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEccG6Ta-xNu"
   },
   "source": [
    "We can also visualize individual predictions to better understand where the model is making mistakes. We want to see if these are these mistakes a human would make, or if there is there something fundamentally amiss how our model operates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "7Robzxwh-xNv",
    "outputId": "7294218d-9c15-423f-c531-4f06edc27779"
   },
   "outputs": [],
   "source": [
    "# Plot the predicted probabilities for individual images\n",
    "# Based on: https://www.kaggle.com/faressayah/cifar-10-image-classification-using-cnns-88\n",
    "\n",
    "def plot_image(predictions, true_label, image):\n",
    "    \"\"\"Plot the image with custom title.\"\"\"\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # transform back our image to the right scale and form\n",
    "    inverse_normalized = image.transpose(0, 2).transpose(0,1) * (0.5) + 0.5\n",
    "    plt.imshow(inverse_normalized, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions)\n",
    "    predicted_class, true_class = class_labels[int(predicted_label)], class_labels[int(true_label)]\n",
    "    label_text = f\"{predicted_class} {100*np.max(predictions):2.0f}% ({true_class})\" \n",
    "    \n",
    "    plt.xlabel(label_text, color=\"black\", fontsize=10)\n",
    "\n",
    "def plot_value_array(predictions, true_label):\n",
    "    \"\"\"Plot the predicted probabilities with color coding.\"\"\"\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#e7aba0')\n",
    "    thisplot[true_label].set_color('#9fb9e8')\n",
    "    \n",
    "    \n",
    "num_rows = 5\n",
    "num_cols = 5\n",
    "num_images = num_rows * num_cols\n",
    "\n",
    "np.random.seed(1)\n",
    "sample_indices = np.random.choice(len(test_dataset), num_images, replace=False)\n",
    "\n",
    "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "\n",
    "# Turn on \"Evaluation mode\"\n",
    "new_CNN_model.eval()\n",
    "\n",
    "for i, sample_idx in enumerate(sample_indices):\n",
    "    input_image, label = test_dataset[sample_idx]\n",
    "    predictions = new_CNN_model(input_image.unsqueeze(0)).squeeze()\n",
    "\n",
    "    predictions = predictions.data.numpy()\n",
    "    \n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "    plot_image(predictions, label, input_image)\n",
    "    \n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(predictions, label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "sns.despine(left=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqyXeSQR-xNx"
   },
   "source": [
    "### What does the CNN model predict for randomized input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wIJCIQE-xNx"
   },
   "source": [
    "Using the same plot, we can look at how the model behaves if provided random input. Surprisingly, we almost always get the same prediction despite the randomness in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQzAXjk97V7K",
    "outputId": "61e2c0cd-967d-4d1e-aca2-aba6c77d293d"
   },
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 5\n",
    "num_images = num_rows * num_cols\n",
    "\n",
    "sample_indices = np.random.choice(len(test_dataset), num_images, replace=False)\n",
    "\n",
    "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "\n",
    "new_CNN_model.eval()\n",
    "for i, sample_idx in enumerate(sample_indices):\n",
    "    input_image, label = torch.rand(3, 32, 32), torch.tensor([0]) # random input and dummy target\n",
    "    predictions = new_CNN_model(input_image.unsqueeze(0)).squeeze()\n",
    "    predictions = predictions.data.numpy()\n",
    "      \n",
    "    \n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "    plot_image(predictions, label, input_image)\n",
    "    \n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(predictions, label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "sns.despine(left=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc4wOW8l-xN0"
   },
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:25px\"\"width: 50px\" src =\"https://drive.google.com/uc?export=view&id=14VoXUJftgptWtdNhtNYVm6cjVmEWpki1\" />\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Ew8Z1ospnZU2"
   ],
   "name": "PyTorch_V1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002a962bd9ea4c279af3e0f9a9c71bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0532641b2afa45519e52cd3e829c88cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcfc9e22ae0342d09c08f31a98f7f17e",
       "IPY_MODEL_3c6afa5c29d844e995fe8c42aae193e2"
      ],
      "layout": "IPY_MODEL_59a57751bf0c4bb2b667cb02456633cf"
     }
    },
    "0c58a233b2734de2b98f8854f6f02703": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "111b298a8eb94eb7bf90b55435b034fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "210dcabc206446d5929c71ec19d0daa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b683d45eea3d495a88f189c3115d8c33",
      "placeholder": "",
      "style": "IPY_MODEL_9b7165ffd0a5450b92dbfdcec2e41b35",
      "value": " 2/2 [04:37&lt;00:00, 138.64s/it]"
     }
    },
    "29e9aa1de2dd4bd98392e42e8325de4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31eaea7a6aaa46a3a4f76668ce21bcc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37484f85f8cf48719e9384bd3d096018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c6afa5c29d844e995fe8c42aae193e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76485cbb91484b4eab6cafb19ae81687",
      "placeholder": "",
      "style": "IPY_MODEL_a4b6700f527c4407af1bd00b7001abd9",
      "value": " 12500/12500 [04:37&lt;00:00, 45.09it/s]"
     }
    },
    "3e047beefd6141bca64b65b6f8341f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c87b9cf462446f58eba68b49d967598",
      "placeholder": "",
      "style": "IPY_MODEL_a7c91a493549482b859ceb8d14633d93",
      "value": " 100/100 [00:02&lt;00:00, 46.34it/s]"
     }
    },
    "3eb405247a4f43788d8dd84b3decbfa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73db760e8951472680fbc843dd2ebf2b",
      "placeholder": "",
      "style": "IPY_MODEL_37484f85f8cf48719e9384bd3d096018",
      "value": " 12500/12500 [03:14&lt;00:00, 64.21it/s]"
     }
    },
    "429c50009273481b8c34e5a48e325a53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44f933f34ce5421181f587b8651efb1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7c2c23dcadd4dc4a80115bf3e7e1133",
       "IPY_MODEL_b68960e273b04f07b6b53e76d7cf0e89"
      ],
      "layout": "IPY_MODEL_0c58a233b2734de2b98f8854f6f02703"
     }
    },
    "538b92bc691344b9b7a914e400e59dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5851c7f2ea1e417e81a271d735314fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a57751bf0c4bb2b667cb02456633cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6af7b49d1ae544b5893bd622b0f6d63e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d931e2ee657243b592df59197e48991d",
       "IPY_MODEL_3eb405247a4f43788d8dd84b3decbfa1"
      ],
      "layout": "IPY_MODEL_5851c7f2ea1e417e81a271d735314fe2"
     }
    },
    "73db760e8951472680fbc843dd2ebf2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76485cbb91484b4eab6cafb19ae81687": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ab9a58e7d64db0b16e16ae9762c955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_feb53e7a895b4a64be2bbf9a2669aee8",
       "IPY_MODEL_3e047beefd6141bca64b65b6f8341f9f"
      ],
      "layout": "IPY_MODEL_429c50009273481b8c34e5a48e325a53"
     }
    },
    "7c87b9cf462446f58eba68b49d967598": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88fa81edd8af4b538c76307b33031ddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90c85db8a5014df1839233b7cacd5daa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Total epochs: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce9349b1ad3948f9ba9cd2ccee3d91be",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9dee2becf77342cb83efa992e48b2bfc",
      "value": 2
     }
    },
    "980cffa23d9f48e28597d0d854281d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b7165ffd0a5450b92dbfdcec2e41b35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dee2becf77342cb83efa992e48b2bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a4b6700f527c4407af1bd00b7001abd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7c91a493549482b859ceb8d14633d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b21bd7e5865f4f6886bd0b14017dab3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b683d45eea3d495a88f189c3115d8c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b68960e273b04f07b6b53e76d7cf0e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b21bd7e5865f4f6886bd0b14017dab3d",
      "placeholder": "",
      "style": "IPY_MODEL_d5711cf01c6b4012ad12fe368fa8fb14",
      "value": " 170500096/? [00:30&lt;00:00, 17485708.50it/s]"
     }
    },
    "ce2f4024aec349448e1ad8c9d5bf0850": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce9349b1ad3948f9ba9cd2ccee3d91be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5711cf01c6b4012ad12fe368fa8fb14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d85bc0a5ce3e4261ad9294f1a0f288ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d931e2ee657243b592df59197e48991d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 1: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_980cffa23d9f48e28597d0d854281d4f",
      "max": 12500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d85bc0a5ce3e4261ad9294f1a0f288ff",
      "value": 12500
     }
    },
    "dcfc9e22ae0342d09c08f31a98f7f17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 0: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29e9aa1de2dd4bd98392e42e8325de4b",
      "max": 12500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_002a962bd9ea4c279af3e0f9a9c71bfb",
      "value": 12500
     }
    },
    "e7c2c23dcadd4dc4a80115bf3e7e1133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_538b92bc691344b9b7a914e400e59dc6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88fa81edd8af4b538c76307b33031ddf",
      "value": 1
     }
    },
    "fdf8c854c1664e3eb100a3efcedc2c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90c85db8a5014df1839233b7cacd5daa",
       "IPY_MODEL_210dcabc206446d5929c71ec19d0daa0"
      ],
      "layout": "IPY_MODEL_31eaea7a6aaa46a3a4f76668ce21bcc1"
     }
    },
    "feb53e7a895b4a64be2bbf9a2669aee8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Total epochs: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce2f4024aec349448e1ad8c9d5bf0850",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_111b298a8eb94eb7bf90b55435b034fe",
      "value": 100
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
